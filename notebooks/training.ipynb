import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense

data = np.load("data/processed_data.npz", allow_pickle=True)
questions = data["questions"]
answers = data["answers"]
word_index = data["word_index"].item()
vocab_size = len(word_index) + 1
max_len = 20

# Model
embedding_dim = 256
lstm_units = 512

# Encoder
encoder_input = Input(shape=(max_len,))
enc_embed = Embedding(vocab_size, embedding_dim)(encoder_input)
encoder_outputs, state_h, state_c = LSTM(lstm_units, return_state=True)(enc_embed)
encoder_states = [state_h, state_c]

# Decoder
decoder_input = Input(shape=(max_len,))
dec_embed = Embedding(vocab_size, embedding_dim)(decoder_input)
decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(dec_embed, initial_state=encoder_states)
decoder_dense = Dense(vocab_size, activation='softmax')
decoder_outputs = decoder_dense(decoder_outputs)

# Compile
model = Model([encoder_input, decoder_input], decoder_outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')

# Prepare decoder target (answers shifted by 1)
decoder_target = np.zeros_like(answers)
decoder_target[:, :-1] = answers[:, 1:]

model.fit([questions, answers], 
          np.expand_dims(decoder_target, -1), 
          batch_size=64, 
          epochs=50)

model.save("model/chatbot_model.h5")
